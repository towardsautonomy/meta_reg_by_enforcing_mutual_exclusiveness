{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_meta_reg_Black_box.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvkoC8rAYBE7"
      },
      "source": [
        "\n",
        "##Setup\n",
        "\n",
        "You will need to make a copy of this Colab notebook in your Google Drive before you can edit the homework files. You can do so with **File &rarr; Save a copy in Drive**.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q4lGYC_E6QQ"
      },
      "source": [
        "import os\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "#! ls /content\n",
        "#!ls /content/gdrive/My\\ Drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNfQ4cWaK_m0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d728ea-7009-472b-939d-383c77b24f5c"
      },
      "source": [
        "import os\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "# Need to download the Omniglot dataset -- DON'T MODIFY THIS CELL\n",
        "if not os.path.isdir('./omniglot_resized'):\n",
        "    gdd.download_file_from_google_drive(file_id='1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI',\n",
        "                                        dest_path='./omniglot_resized.zip',\n",
        "                                        unzip=True)\n",
        "    \n",
        "assert os.path.isdir('./omniglot_resized')\n",
        "print('done')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1iaSFXIYC3AB8q9K_M-oVMa4pmB7yKMtI into ./omniglot_resized.zip... Done.\n",
            "Unzipping...Done.\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucYsULp9HUJy"
      },
      "source": [
        "\"\"\"Data loading scripts\"\"\"\n",
        "## NOTE: You do not need to modify this block but you will need to use it.\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from scipy import misc\n",
        "import imageio\n",
        "\n",
        "def get_images(paths, labels, n_samples=None, shuffle=True):\n",
        "  \"\"\"\n",
        "  Takes a set of character folders and labels and returns paths to image files\n",
        "  paired with labels.\n",
        "  Args:\n",
        "    paths: A list of character folders\n",
        "    labels: List or numpy array of same length as paths\n",
        "    n_samples: Number of images to retrieve per character\n",
        "  Returns:\n",
        "    List of (label, image_path) tuples\n",
        "  \"\"\"\n",
        "  if n_samples is not None:\n",
        "    sampler = lambda x: random.sample(x, n_samples)\n",
        "  else:\n",
        "    sampler = lambda x: x\n",
        "  images_labels = [(i, os.path.join(path, image))\n",
        "           for i, path in zip(labels, paths)\n",
        "           for image in sampler(os.listdir(path))]\n",
        "  if shuffle:\n",
        "    random.shuffle(images_labels)\n",
        "  return images_labels\n",
        "\n",
        "\n",
        "def image_file_to_array(filename, dim_input):\n",
        "  \"\"\"\n",
        "  Takes an image path and returns numpy array\n",
        "  Args:\n",
        "    filename: Image filename\n",
        "    dim_input: Flattened shape of image\n",
        "  Returns:\n",
        "    1 channel image\n",
        "  \"\"\"\n",
        "  image = imageio.imread(filename)\n",
        "  image = image.reshape([dim_input])\n",
        "  image = image.astype(np.float32) / 255.0\n",
        "  image = 1.0 - image\n",
        "  return image\n",
        "\n",
        "\n",
        "class DataGenerator(object):\n",
        "  \"\"\"\n",
        "  Data Generator capable of generating batches of Omniglot data.\n",
        "  A \"class\" is considered a class of omniglot digits.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, num_classes, num_samples_per_class,train_type ='memorization', config={}):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      num_classes: Number of classes for classification (K-way)\n",
        "      num_samples_per_class: num samples to generate per class in one batch\n",
        "      num_meta_test_classes: Number of classes for classification (K-way) at meta-test time\n",
        "      num_meta_test_samples_per_class: num samples to generate per class in one batch at meta-test time\n",
        "      batch_size: size of meta batch size (e.g. number of functions)\n",
        "    \"\"\"\n",
        "    self.num_samples_per_class = num_samples_per_class\n",
        "    self.num_classes = num_classes\n",
        "    self.train_type = train_type\n",
        "\n",
        "    data_folder = config.get('data_folder', './omniglot_resized')\n",
        "    self.img_size = config.get('img_size', (28, 28))\n",
        "\n",
        "    self.dim_input = np.prod(self.img_size)\n",
        "    self.dim_output = self.num_classes\n",
        "\n",
        "    character_folders = [os.path.join(data_folder, family, character)\n",
        "               for family in os.listdir(data_folder)\n",
        "               if os.path.isdir(os.path.join(data_folder, family))\n",
        "               for character in os.listdir(os.path.join(data_folder, family))\n",
        "               if os.path.isdir(os.path.join(data_folder, family, character))]\n",
        "\n",
        "    random.seed(123)\n",
        "    #random.shuffle(character_folders)\n",
        "    num_val = 400\n",
        "    num_train = 1200\n",
        "    self.metatrain_character_folders = character_folders[: num_train]\n",
        "    self.metaval_character_folders = character_folders[\n",
        "      num_train:num_train + num_val]\n",
        "    self.metatest_character_folders = character_folders[\n",
        "      num_train + num_val:]\n",
        "    \n",
        "    print(\"Number of training examples. : \",len(self.metatrain_character_folders))\n",
        "    print(\"Number of validation examples: \",len(self.metaval_character_folders))\n",
        "    print(\"Number of test examples      : \",len(self.metatest_character_folders))\n",
        "    print(\"Training Type: \",self.train_type)\n",
        "\n",
        "    if self.train_type == 'memorization':\n",
        "      self.metatrain_label = [i%self.num_classes for i in range(len(self.metatrain_character_folders))]\n",
        "      self.metaval_label = [i%self.num_classes for i in range(len(self.metaval_character_folders))]\n",
        "      self.metatest_label = [i%self.num_classes for i in range(len(self.metatest_character_folders))]\n",
        "\n",
        "  def sample_batch(self, batch_type, batch_size, shuffle=True, swap=False):\n",
        "    \"\"\"\n",
        "    Samples a batch for training, validation, or testing\n",
        "    Args:\n",
        "      batch_type: meta_train/meta_val/meta_test\n",
        "      shuffle: randomly shuffle classes or not\n",
        "      swap: swap number of classes (N) and number of samples per class (K) or not\n",
        "    Returns:\n",
        "      A a tuple of (1) Image batch and (2) Label batch where\n",
        "      image batch has shape [B, N, K, 784] and label batch has shape [B, N, K, N] if swap is False\n",
        "      where B is batch size, K is number of samples per class, N is number of classes\n",
        "    \"\"\"\n",
        "    if batch_type == \"meta_train\":\n",
        "      folders = self.metatrain_character_folders\n",
        "      num_classes = self.num_classes\n",
        "      num_samples_per_class = self.num_samples_per_class\n",
        "      if self.train_type == 'memorization':\n",
        "        class_label = self.metatrain_label\n",
        "    elif batch_type == \"meta_val\":\n",
        "      folders = self.metaval_character_folders\n",
        "      num_classes = self.num_classes\n",
        "      num_samples_per_class = self.num_samples_per_class\n",
        "      if self.train_type == 'memorization':\n",
        "        class_label = self.metaval_label\n",
        "    elif batch_type == \"meta_test\":\n",
        "      folders = self.metatest_character_folders\n",
        "      num_classes = self.num_classes\n",
        "      num_samples_per_class = self.num_samples_per_class\n",
        "      if self.train_type == 'memorization':\n",
        "        class_label = self.metatest_label\n",
        "    else:\n",
        "      raise Exception('undefied data type')\n",
        "\n",
        "    all_image_batches, all_label_batches = [], []\n",
        "    total_sample = [val for val in range(len(folders))]\n",
        "    for i in range(batch_size):\n",
        "      data_list = random.sample(total_sample, num_classes)\n",
        "      #print(\"data_list: \",data_list)\n",
        "      sampled_character_folders = [folders[n_val] for n_val in data_list]\n",
        "      if self.train_type == 'memorization':\n",
        "        sampled_label = [class_label[n_val] for n_val in data_list]\n",
        "      else:\n",
        "        sampled_label = [n_val for n_val in range(num_classes)]\n",
        "      #print(\"sampled_label:\",sampled_label)\n",
        "      #print(\"sampled_character_folders: \",sampled_character_folders)\n",
        "      labels_and_images = get_images(sampled_character_folders,sampled_label,n_samples=num_samples_per_class,shuffle=False)\n",
        "      labels = [li[0] for li in labels_and_images]\n",
        "      images = [image_file_to_array(\n",
        "        li[1], self.dim_input) for li in labels_and_images]\n",
        "      images = np.stack(images)\n",
        "      labels = np.array(labels).astype(np.int32)\n",
        "      labels = np.reshape(\n",
        "        labels, (num_classes, num_samples_per_class))\n",
        "      labels = np.eye(num_classes, dtype=np.float32)[labels]\n",
        "      images = np.reshape(\n",
        "        images, (num_classes, num_samples_per_class, -1))\n",
        "\n",
        "      batch = np.concatenate([labels, images], 2)\n",
        "      if shuffle:\n",
        "        for p in range(num_samples_per_class):\n",
        "          np.random.shuffle(batch[:, p])\n",
        "\n",
        "      labels = batch[:, :, :num_classes]\n",
        "      images = batch[:, :, num_classes:]\n",
        "\n",
        "      if swap:\n",
        "        labels = np.swapaxes(labels, 0, 1)\n",
        "        images = np.swapaxes(images, 0, 1)\n",
        "\n",
        "      all_image_batches.append(images)\n",
        "      all_label_batches.append(labels)\n",
        "    all_image_batches = np.stack(all_image_batches)\n",
        "    all_label_batches = np.stack(all_label_batches)\n",
        "    return all_image_batches.astype(np.float32), all_label_batches.astype(np.float32)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUY3oxIQHk6c"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "class MANN_UPDATE(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, num_classes, samples_per_class):\n",
        "        super(MANN_UPDATE, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.samples_per_class = samples_per_class\n",
        "        self.conv1 =  tf.keras.layers.Conv2D(8, 3, padding='same', activation=None,data_format=\"channels_last\")\n",
        "        self.maxpool_1 = tf.keras.layers.MaxPooling2D(pool_size=2,data_format=\"channels_last\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 =  tf.keras.layers.Conv2D(16, 3, padding='same', activation=None,data_format=\"channels_last\")\n",
        "        self.maxpool_2 = tf.keras.layers.MaxPooling2D(pool_size=2,data_format=\"channels_last\")\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.flatten = tf.keras.layers.Flatten(data_format=\"channels_last\")\n",
        "        self.layer1 = tf.keras.layers.LSTM(256, return_sequences=True)\n",
        "        self.layer2 = tf.keras.layers.LSTM(num_classes, return_sequences=True)\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, input_images, input_labels,training):\n",
        "        \"\"\"\n",
        "        MANN\n",
        "        Args:\n",
        "            input_images: [B, K+1, N, 784] flattened images\n",
        "            labels: [B, K+1, N, N] ground truth labels\n",
        "        Returns:\n",
        "            [B, K+1, N, N] predictions\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        #### YOUR CODE GOES HERE ####\n",
        "        #print(\"input_images,\",input_images.shape,input_labels.shape)\n",
        "        x = tf.reshape(input_images, [input_images.shape[0]*self.num_classes*self.samples_per_class,-1])\n",
        "        x = tf.reshape(x, [x.shape[0],28,28,1])\n",
        "        # do a convoultion on the image\n",
        "        #conv1\n",
        "        x_conv1 = self.conv1(x)\n",
        "        x_conv1 = self.bn1(x_conv1, training=training)\n",
        "        x_conv1 = tf.nn.relu(x_conv1)\n",
        "        x_maxpool_1 = self.maxpool_1(x_conv1)\n",
        "        #conv2\n",
        "        x_conv2 = self.conv2(x_maxpool_1)\n",
        "        x_conv2 = self.bn2(x_conv2, training=training)\n",
        "        x_conv2 = tf.nn.relu(x_conv2)\n",
        "        x_maxpool_2 = self.maxpool_2(x_conv2)\n",
        "        #flatten the feature\n",
        "        x_flatten = self.flatten(x_maxpool_2)\n",
        "        x_feature = tf.reshape(x_flatten, [input_images.shape[0],self.samples_per_class,self.num_classes,-1])\n",
        "        #mask labels of last N images\n",
        "        mask_vector = tf.zeros([input_labels.shape[0],1,self.num_classes,self.num_classes],dtype=tf.dtypes.float32)\n",
        "        masked_label = tf.concat([input_labels[:,:self.samples_per_class-1,:,:], mask_vector], 1)\n",
        "        meta_input = tf.concat([x_feature, masked_label], 3)\n",
        "        meta_input_flatten = tf.reshape(meta_input, [input_images.shape[0],self.num_classes*self.samples_per_class,-1])\n",
        "        # LSTM (MANN block) \n",
        "        hx = self.layer1(meta_input_flatten)\n",
        "        logit = self.layer2(hx)\n",
        "        out = tf.reshape(logit, [input_images.shape[0],self.samples_per_class,self.num_classes,-1])\n",
        "        #############################\n",
        "        return out,hx,meta_input_flatten\n",
        "\n",
        "    def loss_function(self, preds, labels):\n",
        "        \"\"\"\n",
        "        Computes MANN loss\n",
        "        Args:\n",
        "            preds: [B, K+1, N, N] network output\n",
        "            labels: [B, K+1, N, N] labels\n",
        "        Returns:\n",
        "            scalar loss\n",
        "        \"\"\"\n",
        "        #############################\n",
        "        loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "        loss = loss_object(labels[:,self.samples_per_class-1:,:,:],preds[:,self.samples_per_class-1:,:,:])\n",
        "        return loss\n",
        "        #############################\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step_update(images, labels, model, optim, eval=False,training=False):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions,hx,latent_x = model(images, labels,training=training)\n",
        "        h_summary = hx[:,4,:]\n",
        "        x_latent = latent_x[:,:5,:]\n",
        "        z_task = tf.reduce_mean(x_latent,axis=1)\n",
        "        #print(hx.shape,latent_x.shape)\n",
        "        #print(\"h_summary:\",h_summary.shape,x_latent.shape,z_task.shape)\n",
        "        #compute meta_reg value\n",
        "        batch_dim = hx.shape[0]\n",
        "        count =0\n",
        "        if not eval:\n",
        "          for i in range(0,batch_dim-1):\n",
        "            for j in range(i+1,batch_dim):\n",
        "              count+=1\n",
        "            #   zz = tf.stop_gradient(tf.norm(z_task[i] - z_task[j],ord='euclidean')) \n",
        "              zz = tf.norm(z_task[i] - z_task[j],ord='euclidean')\n",
        "              hval = tf.norm(h_summary[i] - h_summary[j],ord='euclidean')\n",
        "            #   print(hval)\n",
        "              l2_norm = tf.abs(1.0 - (hval/zz))\n",
        "              l2_norm = hval/zz\n",
        "              if i == 0 and j == 1:\n",
        "                meta_reg = l2_norm\n",
        "                z_dist = zz\n",
        "                h_dist = hval\n",
        "              else:\n",
        "                meta_reg = meta_reg + l2_norm\n",
        "                z_dist = z_dist + zz\n",
        "                h_dist = h_dist + hval\n",
        "\n",
        "          meta_reg = meta_reg / count\n",
        "          z_dist = z_dist / count\n",
        "          h_dist = h_dist / count\n",
        "        else:\n",
        "          meta_reg = 0.0\n",
        "          z_dist = 0.0\n",
        "          h_dist = 0.0\n",
        "        #print(meta_reg,batch_dim,count)\n",
        "        pred_loss = model.loss_function(predictions, labels)\n",
        "        if not eval:\n",
        "          loss = pred_loss + meta_reg\n",
        "        else:\n",
        "          loss = pred_loss\n",
        "    if not eval:\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optim.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return predictions, loss, pred_loss, meta_reg,z_dist,h_dist\n",
        "\n",
        "\n",
        "def main_update(num_classes=5, num_samples=1, meta_batch_size=16, random_seed=1234,train_type='no_memorization'):\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    tf.random.set_seed(random_seed)\n",
        "\n",
        "    data_generator = DataGenerator(num_classes, num_samples + 1,train_type=train_type)\n",
        "\n",
        "    o = MANN_UPDATE(num_classes, num_samples + 1)\n",
        "    optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    test_acc = []\n",
        "    train_acc = []\n",
        "    meta_reg_trj = []\n",
        "    z_dist_trj = []\n",
        "    h_dist_trj = []\n",
        "    step_num = []\n",
        "\n",
        "    for step in range(15000): \n",
        "        i, l = data_generator.sample_batch('meta_train', meta_batch_size,swap=True)\n",
        "        _, ls,pre_loss, meta_reg,z_dist,h_dist = train_step_update(i, l, o, optim,eval=False,training=True)\n",
        "\n",
        "        if (step + 1) % 100 == 0:\n",
        "            print(\"*\" * 5 + \"Iter \" + str(step + 1) + \"*\" * 5)\n",
        "            #compute training accuracy\n",
        "            i, l = data_generator.sample_batch('meta_train', 100,swap=True)\n",
        "            pred, _,tls,_,_,_ = train_step_update(i, l, o, optim, eval=True,training=False)\n",
        "            pred = tf.reshape(pred, [-1, num_samples + 1, num_classes, num_classes])\n",
        "            pred = tf.math.argmax(pred[:, -1, :, :], axis=2)\n",
        "            l = tf.math.argmax(l[:, -1, :, :], axis=2)\n",
        "            cur_train_acc =  tf.reduce_mean(tf.cast(tf.math.equal(pred, l), tf.float32)).numpy()\n",
        "            #compute test\n",
        "            i, l = data_generator.sample_batch('meta_val', 100,swap=True)\n",
        "            pred,_,tls,_,_,_ = train_step_update(i, l, o, optim, eval=True,training=False)\n",
        "            print(\"Train Loss:\", pre_loss.numpy(), \"Test Loss:\", tls.numpy())\n",
        "            print(\"Train Loss:\", ls.numpy(), \"Predict_loss:\", pre_loss.numpy(),'Meta_reg:',meta_reg.numpy(),\n",
        "                  'H_dist:',h_dist.numpy(),'Z_dist:',z_dist.numpy())\n",
        "            step_num.append(step)\n",
        "            train_loss.append(ls.numpy())\n",
        "            meta_reg_trj.append(meta_reg.numpy())\n",
        "            z_dist_trj.append(z_dist.numpy())\n",
        "            h_dist_trj.append(h_dist.numpy())\n",
        "            test_loss.append(tls.numpy())\n",
        "            pred = tf.reshape(pred, [-1, num_samples + 1, num_classes, num_classes])\n",
        "            pred = tf.math.argmax(pred[:, -1, :, :], axis=2)\n",
        "            l = tf.math.argmax(l[:, -1, :, :], axis=2)\n",
        "            print(\"Train Accuracy\", cur_train_acc)\n",
        "            print(\"Test Accuracy\", tf.reduce_mean(tf.cast(tf.math.equal(pred, l), tf.float32)).numpy())\n",
        "            test_acc.append(tf.reduce_mean(tf.cast(tf.math.equal(pred, l), tf.float32)).numpy())\n",
        "            train_acc.append(cur_train_acc)\n",
        "    return step_num,train_loss,test_loss,test_acc,train_acc,meta_reg_trj,z_dist_trj,h_dist_trj,o"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c2hBii6Om6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "41372d99-6d99-48b9-b133-25b57644ecdd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "step_num,train_loss,test_loss,test_acc,train_acc,meta_reg,z_dist,h_dist,model = main_update(num_classes=10, num_samples=1, \n",
        "                                                     meta_batch_size=32, random_seed=1234,train_type='memorization')\n",
        "\n",
        "#input_images, (64, 2, 20, 784) (64, 2, 20, 20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples. :  1200\n",
            "Number of validation examples:  400\n",
            "Number of test examples      :  23\n",
            "Training Type:  memorization\n",
            "*****Iter 100*****\n",
            "Train Loss: 2.302045 Test Loss: 2.3034213\n",
            "Train Loss: 2.3021152 Predict_loss: 2.302045 Meta_reg: 7.012442e-05 H_dist: 0.00091832783 Z_dist: 13.385356\n",
            "Train Accuracy 0.094\n",
            "Test Accuracy 0.102\n",
            "*****Iter 200*****\n",
            "Train Loss: 2.3042572 Test Loss: 2.3030334\n",
            "Train Loss: 2.3043027 Predict_loss: 2.3042572 Meta_reg: 4.5488636e-05 H_dist: 0.00060637994 Z_dist: 13.627498\n",
            "Train Accuracy 0.1\n",
            "Test Accuracy 0.091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-087064074964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m step_num,train_loss,test_loss,test_acc,train_acc,meta_reg,z_dist,h_dist,model = main_update(num_classes=10, num_samples=1, \n\u001b[0;32m----> 3\u001b[0;31m                                                      meta_batch_size=32, random_seed=1234,train_type='memorization')\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#input_images, (64, 2, 20, 784) (64, 2, 20, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-64cbed1e39ab>\u001b[0m in \u001b[0;36mmain_update\u001b[0;34m(num_classes, num_samples, meta_batch_size, random_seed, train_type)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'meta_train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_batch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mswap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz_dist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_step_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-2290955d7471>\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m(self, batch_type, batch_size, shuffle, swap)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_and_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       images = [image_file_to_array(\n\u001b[0;32m--> 148\u001b[0;31m         li[1], self.dim_input) for li in labels_and_images]\n\u001b[0m\u001b[1;32m    149\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-2290955d7471>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mli\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mli\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels_and_images\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       images = [image_file_to_array(\n\u001b[0;32m--> 148\u001b[0;31m         li[1], self.dim_input) for li in labels_and_images]\n\u001b[0m\u001b[1;32m    149\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m       \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-2290955d7471>\u001b[0m in \u001b[0;36mimage_file_to_array\u001b[0;34m(filename, dim_input)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;36m1\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m   \"\"\"\n\u001b[0;32m---> 42\u001b[0;31m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# Return its reader object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;34m\"Format %s cannot read in mode %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselect_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             )\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/core/format.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, format, request)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0;31m# Open the reader/writer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, pilmode, as_gray, ignoregamma)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPillowFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpilmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignoregamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPillowFormat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpilmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpilmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_gray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/imageio/plugins/pillow.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, pilmode, as_gray)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Format %s cannot read images.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_decompression_bomb_check\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompression_bomb_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fp, filename)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             except (\n\u001b[1;32m    109\u001b[0m                 \u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# end of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_MAGIC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not a PNG file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRKZp1-gOxOJ"
      },
      "source": [
        "plt.rcParams[\"font.weight\"] = \"bold\"\n",
        "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
        "fig, ax = plt.subplots(1,3,figsize=(16,4))\n",
        "val = 125\n",
        "ax[0].plot(step_num[:val],test_acc[:val],linewidth=2,c='b',)\n",
        "ax[0].plot(step_num[:val],train_acc[:val],linewidth=2,c='r',)\n",
        "ax[1].plot(step_num[:val],h_dist[:val],linewidth=2,c='b',)\n",
        "ax[1].plot(step_num[:val],z_dist[:val],linewidth=2,c='r',)\n",
        "ax[1].plot(step_num[:val],np.asarray(h_dist[:val])/np.asarray(z_dist[:val]),linewidth=2,c='g',)\n",
        "ax[2].plot(step_num[:val],train_loss[:val],linewidth=2,c='r')\n",
        "ax[2].plot(step_num[:val],test_loss[:val],linewidth=2,c='b')\n",
        "ax[2].legend(['train loss','test loss'],loc=1,prop={'size': 14})\n",
        "ax[0].legend(['train acc','test acc'],loc=4,prop={'size': 14})\n",
        "ax[1].legend(['h_dist','z_dist', 'h_dist/z_dist'],loc=1,prop={'size': 12})\n",
        "ax[0].set_ylabel('Train/Test Accuracy',weight='bold',fontsize=16)\n",
        "ax[1].set_ylabel('Task Distance',weight='bold',fontsize=16)\n",
        "ax[2].set_ylabel('Train/Test Loss',weight='bold',fontsize=16)\n",
        "ax[0].set_xlabel('Epochs',weight='bold',fontsize=16)\n",
        "ax[1].set_xlabel('Epochs',weight='bold',fontsize=16)\n",
        "ax[2].set_xlabel('Epochs',weight='bold',fontsize=16)\n",
        "\n",
        "#ax[0].set_xlim(0,15000)\n",
        "#ax[1].set_xlim(0,15000)\n",
        "#ax[2].set_xlim(0,15000)\n",
        "fig.suptitle('K=1 and N=10', fontsize=18,weight='bold')\n",
        "plt.savefig('k_1_N-10_batch32-meta-reg-ratio-4-256.png',dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04naASq1pC_W"
      },
      "source": [
        "np.save('step_num.npy',step_num)\n",
        "np.save('train_loss.npy',train_loss)\n",
        "np.save('test_loss.npy',test_loss)\n",
        "np.save('test_acc.npy',test_acc)\n",
        "np.save('train_acc.npy',train_acc)\n",
        "model.save_weights('meta-reg-ratio-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQfKptyMIaWn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}